{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules for Scientific Computing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object-oriented programming is one of the most effective approaches to writing software. In object-oriented programming you write classes that represent real-world things and situations, and you create objects based on these classes. When you write a class, you define the general behavior that a whole category of objects can have. When you create individual objects from the class, each object is automatically equipped with the general behavior; you can then give each object whatever unique traits you desire. You’ll be amazed how well real-world situations can be modeled with object-oriented programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock():\n",
    "    \"\"\"A simple class to model a stock\"\"\"\n",
    "    \n",
    "    def __init__(self, name, ticker, market_cap, time_series):\n",
    "        self.name = name\n",
    "        self.ticker = ticker\n",
    "        self.market_cap = market_cap\n",
    "        self.time_series = time_series\n",
    "        \n",
    "    def add_price(self,date,price):\n",
    "        self.time_series[date] = price\n",
    "        \n",
    "    def change_market_cap(self,new_cap):\n",
    "        self.market_cap = new_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_stock = Stock(\"Apple\", \"AAPL\", 1000000000000, {\"2020/8/1\":400.51, \"2020/8/2\":403.45})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020/8/1': 400.51, '2020/8/2': 403.45}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_stock.time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_stock.ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_stock.add_price(\"2020/8/3\",411.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020/8/1': 400.51, '2020/8/2': 403.45, '2020/8/3': 411.6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_stock.time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inheritance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don’t always have to start from scratch when writing a class. If the class you’re writing is a specialized version of another class you wrote, you can use inheritance. When one class inherits from another, it automatically takes on all the attributes and methods of the first class. The original class is called the parent class, and the new class is the child class. The child class inherits every attribute and method from its parent class but is also free to define new attributes and methods of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock_future(Stock):\n",
    "    \n",
    "    def __init__(self, name, ticker, market_cap, time_series, expiry):\n",
    "        super().__init__(name, ticker, market_cap, time_series)\n",
    "        self.expiry = expiry\n",
    "        \n",
    "    def change_expiry(new_expiry):\n",
    "        self.expiry = new_expiry\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_future = Stock_future(\"Apple\", \"AAPL\", 1000000000000, {\"2020/8/1\":400.51, \"2020/8/2\":403.45},\"2020/8/30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020/8/30'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_future.expiry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020/8/1': 400.51, '2020/8/2': 403.45}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_future.time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_future.add_price(\"2020/8/3\",411.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020/8/1': 400.51, '2020/8/2': 403.45, '2020/8/3': 411.6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_future.time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File IO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interfacing with files so that you can import data into your code is going to be very important to use. As we will see there are a number of ways to do this as well as a number of modules that provide the functionality we will need. We will start with the most basic approach, the open() function. This allows us to import a file from a given path and populate various data structures with it's contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415926535 \n",
      "  8979323846 \n",
      "  2643383279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/Users/michael/python_work/pi_digits.txt\"\n",
    "\n",
    "with open(filepath) as file_object:\n",
    "    contents = file_object.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two standard functions in Python for dealing with files; open() and close(). When you open a file it will remain open until you close it. While open the file can be subjected to data loss of corruption if your code does not handle it properly. This is where with comes in. With causes python to automatically close the file once it is no longer needed. This eliminates the need to call the close() function and allows use to keep the file open for a minimum amount of time in order to prevent issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing databases for larger files the first question most programmer ask is \"how many lines is the file\". This is because we typically read files in on a line by line basis. We can do this in python as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415926535 \n",
      "\n",
      "  8979323846 \n",
      "\n",
      "  2643383279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(filepath) as file_object:\n",
    "    lines = file_object.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this with a real file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time|Exchange|Symbol|Sale Condition|Trade Volume|Trade Price|Trade Stop Stock Indicator|Trade Correction Indicator|Sequence Number|Trade Id|Source of Trade|Trade Reporting Facility|Participant Timestamp|Trade Reporting Facility TRF Timestamp|Trade Through Exempt Indicator\n",
      "\n",
      "090004996509000|T|A| FTI|50|65.5|N|00|173001|62879130218317|C||090004995641786||1\n",
      "\n",
      "091705411537000|D|A|  TI|12|65.93|N|00|220701|71675222906168|C|T|091705162000000|091705410778199|0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/Users/michael/Data/EQY_US_ALL_TRADE_20181105\"\n",
    "\n",
    "with open(filepath, 'r') as file_object:\n",
    "    trade_data = file_object.readlines()\n",
    "    \n",
    "for iwho in range(3):\n",
    "    print(trade_data[iwho])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37419536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trade_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just loaded every equity trade which took place on the NYSE on November 5th 2018 into a lilst of strings. You can see the first three strings in the list above. The first one is the header which tells you what each entry means. We will go through the details of these entires as the course evolves.\n",
    "\n",
    "The open() function can also be used to create a file,write out to a file, or append to a file. This just requires us to pass an additional argument. We have done this is the code above. In the second argument we see 'r'. This means open() is in read mode. You can pass 'w' fro write, 'a' for append, and 'r+' for read and write. If you pass nothing python assumes you are in read mode. If you call the write option and no such file exists, python will create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/michael/Data/A_trade.txt\",'w') as file_object:\n",
    "    file_object.write(trade_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "090004996509000|T|A| FTI|50|65.5|N|00|173001|62879130218317|C||090004995641786||1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/michael/Data/A_trade.txt\") as file_object:\n",
    "    print(file_object.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's append some additional trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/michael/Data/A_trade.txt\",'a') as file_object:\n",
    "    for iwhen in range(2,10):\n",
    "        file_object.write(trade_data[iwhen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "090004996509000|T|A| FTI|50|65.5|N|00|173001|62879130218317|C||090004995641786||1\n",
      "091705411537000|D|A|  TI|12|65.93|N|00|220701|71675222906168|C|T|091705162000000|091705410778199|0\n",
      "093000012344000|N|A| O  |16450|66.03|N|00|277801|52983576808518|C||093000003816000||0\n",
      "093031335250000|D|A|   I|48|66.0424|N|00|490501|71675223951689|C|T|093031327000000|093031334543995|0\n",
      "093035234224000|D|A|    |100|66.13|N|00|500201|71675223956051|C|T|093035232000000|093035233601427|0\n",
      "093037106236000|D|A|   I|38|65.89|N|00|502801|71675224012873|C|T|093037103000000|093037105581364|0\n",
      "093037117772000|D|A|    |100|66.1|N|00|502901|71675224012874|C|T|093037111000000|093037117155788|0\n",
      "093040098178000|Y|A|   I|13|65.89|N|00|528301|52983525027918|C||093040097670000||0\n",
      "093046754968000|Z|A|   I|2|65.91|N|00|550801|52983525028417|C||093046754463000||0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/michael/Data/A_trade.txt\") as file_object:\n",
    "    print(file_object.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the | characters through out the file. These are refered to as pipes. NYSE uses pipes as their sperator variable or delimiter instead of commas. Each line in this file represents a trade. The pipes seperate the different peices of information about a particular trade. We would like to change this from a list of string into a list of lists so that we can access each field of a trade directly. In order to do this we will need that csv module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['090004996509000', 'T', 'A', ' FTI', '50', '65.5', 'N', '00', '173001', '62879130218317', 'C', '', '090004995641786', '', '1\\n']\n",
      "['091705411537000', 'D', 'A', '  TI', '12', '65.93', 'N', '00', '220701', '71675222906168', 'C', 'T', '091705162000000', '091705410778199', '0\\n']\n",
      "['093000012344000', 'N', 'A', ' O  ', '16450', '66.03', 'N', '00', '277801', '52983576808518', 'C', '', '093000003816000', '', '0\\n']\n",
      "['093031335250000', 'D', 'A', '   I', '48', '66.0424', 'N', '00', '490501', '71675223951689', 'C', 'T', '093031327000000', '093031334543995', '0\\n']\n",
      "['093035234224000', 'D', 'A', '    ', '100', '66.13', 'N', '00', '500201', '71675223956051', 'C', 'T', '093035232000000', '093035233601427', '0\\n']\n",
      "['093037106236000', 'D', 'A', '   I', '38', '65.89', 'N', '00', '502801', '71675224012873', 'C', 'T', '093037103000000', '093037105581364', '0\\n']\n",
      "['093037117772000', 'D', 'A', '    ', '100', '66.1', 'N', '00', '502901', '71675224012874', 'C', 'T', '093037111000000', '093037117155788', '0\\n']\n",
      "['093040098178000', 'Y', 'A', '   I', '13', '65.89', 'N', '00', '528301', '52983525027918', 'C', '', '093040097670000', '', '0\\n']\n",
      "['093046754968000', 'Z', 'A', '   I', '2', '65.91', 'N', '00', '550801', '52983525028417', 'C', '', '093046754463000', '', '0\\n']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"/Users/michael/Data/A_trade.txt\",newline='\\n') as file_object:\n",
    "   trade_data_A = file_object.readlines()\n",
    "\n",
    "buffer = []\n",
    "\n",
    "for line in trade_data_A:\n",
    "    buffer.append(line.split('|'))\n",
    "\n",
    "trade_data_A = buffer\n",
    "for line in trade_data_A:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python uses object called exceptions to handle errors. Whenever an error occurs an exception is generated. If your code does not know how to handle the exception it will stop running and a trace back error will be returned. We can attempt to anticipate errors using try-except block. This allows our code to handle the anticipated error when it comes up and allows us to prevent a crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0106664d39e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "5/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't divide by 0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    5/0\n",
    "except ZeroDivisionError:\n",
    "    print(\"You can't divide by 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we probably don't want to output messages like this in larger blocks of code, we could write to an error log instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    5/0\n",
    "except ZeroDivisionError:\n",
    "    with open(\"/Users/michael/Documents/Stony Brook/AMS 691 Fall 2020/Lecture002/Errlog.txt\",'w') as file_object:\n",
    "        file_object.write(\"Division by zero attempted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division by zero attempted.\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/michael/Documents/Stony Brook/AMS 691 Fall 2020/Lecture002/Errlog.txt\") as file_object:\n",
    "    log_contents = file_object.read()\n",
    "    print(log_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Python or Numpy is a module which is centered around multidimensional arrays; matrices. It is written in such a way as to allow for fast implementation of these arrays. This allows it to compete with languages like C++ and Fortran when it comes to matrix operations. In quantitative finanace, and computational science more generally, Numpy is indispensable. A good partner module for Numpy is Cupy (which we will not need for this course). Cupy provides Cuda support for Numpy allowing the user to leverage GPUs to accelerate their computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic object in Numpy is the array. Arrays can be used to represent vectors, matrices, tensors, and other objects. Here is a simple example of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vnVector = np.array([1,2,3,4,5])\n",
    "vnVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavior of arrays is very similar to lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnVector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnVector[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnVector[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnVector[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnVector[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "mnMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix[0,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnMatrix[0,1] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways to get the dimension of your array, but shape is probably the one you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all variables in Python the complier makes assumptions about the type elements have in an array. Consider our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 64-bit integer elements. If we wanted floats we should have used decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnFloatMatrix = np.array([[1.2,3.6,-2.1],[0.5,2.2,1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnFloatMatrix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', 'four'], dtype='<U4')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnText = np.array(['1','2','3','four'])\n",
    "vnText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U4')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnText.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arrays can be made from lists or lists of lists\n",
    "my_list = [1,2,3,4,5]\n",
    "mnList = np.array(my_list)\n",
    "mnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A matrix of all zeros\n",
    "mnZeros = np.zeros((3,4))\n",
    "mnZeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A matrix of all ones\n",
    "mnOnes = np.ones((4,3))\n",
    "mnOnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 5, 5],\n",
       "       [5, 5, 5, 5],\n",
       "       [5, 5, 5, 5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More generally full can be used to make an arbitrary size matrix with identical entires\n",
    "mnFives = np.full((3,4),5)\n",
    "mnFives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00000000e+000, 3.11107978e+231],\n",
       "       [9.88131292e-324, 2.82465084e-309]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a random matrix\n",
    "mnRand = np.empty((2,2))\n",
    "mnRand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar to using range is arange in np\n",
    "vnVec = np.arange(6)\n",
    "vnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape allows us to dictate the dimensions of the matrix\n",
    "vnVec.reshape(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can create mnMatrix from above using arange and reshape\n",
    "mnMatrix = np.arange(1,13).reshape(3,4)\n",
    "mnMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnMatrix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can specify data type or step size\n",
    "vnVec1 = np.arange(0,5, dtype=float)\n",
    "vnVec1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2. , 2.5, 3. , 3.5, 4. , 4.5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vnVec2 = np.arange(2,5,0.5)\n",
    "vnVec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identity matrix\n",
    "mnIden = np.identity(3)\n",
    "mnIden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The eye method is similar, but it controls for size\n",
    "mnDiag = np.eye(3,4)\n",
    "mnDiag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You and apply standard arithmetic operators to vectors and matrices in Python, but be aware that they operate pointwise. In order to do matrix multiplication and inverse we must use special Numpy methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(16).reshape((4,4))\n",
    "B = np.arange(1,17).reshape((4,4))\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5  7]\n",
      " [ 9 11 13 15]\n",
      " [17 19 21 23]\n",
      " [25 27 29 31]]\n"
     ]
    }
   ],
   "source": [
    "print(A + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(A - B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   2   6  12]\n",
      " [ 20  30  42  56]\n",
      " [ 72  90 110 132]\n",
      " [156 182 210 240]]\n"
     ]
    }
   ],
   "source": [
    "print(A * B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.5        0.66666667 0.75      ]\n",
      " [0.8        0.83333333 0.85714286 0.875     ]\n",
      " [0.88888889 0.9        0.90909091 0.91666667]\n",
      " [0.92307692 0.92857143 0.93333333 0.9375    ]]\n"
     ]
    }
   ],
   "source": [
    "print(A / B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "print(A % B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3  6  9]\n",
      " [12 15 18 21]\n",
      " [24 27 30 33]\n",
      " [36 39 42 45]]\n"
     ]
    }
   ],
   "source": [
    "print(3*A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also numpy methods like add(), subtract(), multiply(), and divide() which do element wise operations too. There are some methods which do not have symbolic equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5  7]\n",
      " [ 9 11 13 15]\n",
      " [17 19 21 23]\n",
      " [25 27 29 31]]\n"
     ]
    }
   ],
   "source": [
    "print(np.add(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.         1.41421356 1.73205081]\n",
      " [2.         2.23606798 2.44948974 2.64575131]\n",
      " [2.82842712 3.         3.16227766 3.31662479]\n",
      " [3.46410162 3.60555128 3.74165739 3.87298335]]\n"
     ]
    }
   ],
   "source": [
    "#sqrt() takes square roots element wise\n",
    "print(np.sqrt(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "#sum() adds up all the elements in the array\n",
    "print(np.sum(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication is performed using the dot() method. This can also be used on vectors to compute the dot product. Alternativly you can also use matmul()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62  68  74  80]\n",
      " [174 196 218 240]\n",
      " [286 324 362 400]\n",
      " [398 452 506 560]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 80  90 100 110]\n",
      " [176 202 228 254]\n",
      " [272 314 356 398]\n",
      " [368 426 484 542]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(B,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62  68  74  80]\n",
      " [174 196 218 240]\n",
      " [286 324 362 400]\n",
      " [398 452 506 560]]\n"
     ]
    }
   ],
   "source": [
    "#You can also use matmul\n",
    "print(np.matmul(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 80  90 100 110]\n",
      " [176 202 228 254]\n",
      " [272 314 356 398]\n",
      " [368 426 484 542]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(B,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "#The dot product of the first row of A with the first column of B\n",
    "print(np.dot(A[0],B[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the outer product of two vectors. Recall that given an $n \\times 1$ vector $u$ and a $n \\times 1$ vector $v$ we define the outer product $u \\otimes v$ as the $m \\times n$ matrix\n",
    "$$u \\otimes v = \\begin{pmatrix}\n",
    "u_1v_1 & \\cdots & u_1v_n\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "u_mv_1 & \\cdots &u_mv_n\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0]\n",
      " [ 1  5  9 13]\n",
      " [ 2 10 18 26]\n",
      " [ 3 15 27 39]]\n"
     ]
    }
   ],
   "source": [
    "#outer() produces the outer product of two vectors.\n",
    "print(np.outer(A[0],B[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generalization of the outer product to matrices is the Kronecker product. We can do the Kronecker product as well. Recall that given an $n \\times m$ matrix $A$ and a $p \\times q$ matrix $B$ we define the Kronecker product $A \\otimes B$ as the $pm \\times qn$ matrix\n",
    "$$A \\otimes B = \\begin{pmatrix}\n",
    "a_{11}B & \\cdots & a_{1n}B\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1}B & \\cdots &a_{mn}B\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   1   2   3   4   2   4   6   8   3   6   9  12]\n",
      " [  0   0   0   0   5   6   7   8  10  12  14  16  15  18  21  24]\n",
      " [  0   0   0   0   9  10  11  12  18  20  22  24  27  30  33  36]\n",
      " [  0   0   0   0  13  14  15  16  26  28  30  32  39  42  45  48]\n",
      " [  4   8  12  16   5  10  15  20   6  12  18  24   7  14  21  28]\n",
      " [ 20  24  28  32  25  30  35  40  30  36  42  48  35  42  49  56]\n",
      " [ 36  40  44  48  45  50  55  60  54  60  66  72  63  70  77  84]\n",
      " [ 52  56  60  64  65  70  75  80  78  84  90  96  91  98 105 112]\n",
      " [  8  16  24  32   9  18  27  36  10  20  30  40  11  22  33  44]\n",
      " [ 40  48  56  64  45  54  63  72  50  60  70  80  55  66  77  88]\n",
      " [ 72  80  88  96  81  90  99 108  90 100 110 120  99 110 121 132]\n",
      " [104 112 120 128 117 126 135 144 130 140 150 160 143 154 165 176]\n",
      " [ 12  24  36  48  13  26  39  52  14  28  42  56  15  30  45  60]\n",
      " [ 60  72  84  96  65  78  91 104  70  84  98 112  75  90 105 120]\n",
      " [108 120 132 144 117 130 143 156 126 140 154 168 135 150 165 180]\n",
      " [156 168 180 192 169 182 195 208 182 196 210 224 195 210 225 240]]\n"
     ]
    }
   ],
   "source": [
    "#Kronecker product\n",
    "print(np.kron(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to implement the transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4  8 12]\n",
      " [ 1  5  9 13]\n",
      " [ 2  6 10 14]\n",
      " [ 3  7 11 15]]\n"
     ]
    }
   ],
   "source": [
    "print(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4  8 12]\n",
      " [ 1  5  9 13]\n",
      " [ 2  6 10 14]\n",
      " [ 3  7 11 15]]\n"
     ]
    }
   ],
   "source": [
    "print(A.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trace of a matrix\n",
    "A.trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SciPy library is one of the core packages that make up the SciPy stack. It provides many user-friendly and efficient numerical routines, such as routines for numerical integration, interpolation, optimization, linear algebra, and statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The linalg Submodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the other matrix operations and manipulations numpy has are contained in the linalg submodule. Unfortunately this submodule is very light in numpy. Scipy also contains a linalg submodlue. In scipy the submodule can do everything the one in numpy can and much much more. Even some of the linalg functions that numpy and scipy have in common are more limited on the scipy side. In the end you are better off creating arrays in numpy and working with them in scipy most of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnGoodMatrix = np.dot(B,B.T) + np.identity(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve linear equations of the form $$Ax = b$$ for $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4. ,  4.5])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.solve(np.array([[1,2],[3,4]]),np.array([5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492.719665576896\n"
     ]
    }
   ],
   "source": [
    "#Find the Euclidean norm of a matrix or vector\n",
    "print(linalg.norm(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7897.000000000006\n"
     ]
    }
   ],
   "source": [
    "#Compute the determinant of a matrix\n",
    "print(linalg.det(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42889705 -0.33303786 -0.09497277  0.14309231]\n",
      " [-0.33303786  0.73483601 -0.19729011 -0.12941623]\n",
      " [-0.09497277 -0.19729011  0.70039255 -0.40192478]\n",
      " [ 0.14309231 -0.12941623 -0.40192478  0.32556667]]\n"
     ]
    }
   ],
   "source": [
    "#Find the inverse of a matrix\n",
    "print(linalg.inv(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the Moore-Penrose inverse for matrices which are not invertable. Remember this is defined as $$A^+ = (A^*A)^{-1}A$$ when $A$ has linearly independant columns. When it does not this is more generally defined satsifying four conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Notice A is not invertable\n",
    "print(linalg.det(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.62500000e-01 -1.37500000e-01 -1.25000000e-02  1.12500000e-01]\n",
      " [-1.00000000e-01 -5.00000000e-02  1.53250756e-17  5.00000000e-02]\n",
      " [ 6.25000000e-02  3.75000000e-02  1.25000000e-02 -1.25000000e-02]\n",
      " [ 2.25000000e-01  1.25000000e-01  2.50000000e-02 -7.50000000e-02]]\n"
     ]
    }
   ],
   "source": [
    "#pinv() gives the Moore-Penrose inverse\n",
    "print(linalg.pinv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492.719665576896\n"
     ]
    }
   ],
   "source": [
    "#Find the Euclidean norm of a matrix or vector\n",
    "print(linalg.norm(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.49270962e+03+0.j, 5.29037925e+00+0.j, 1.00000000e+00+0.j,\n",
      "       1.00000000e+00+0.j]), array([[-0.13472212,  0.82574206,  0.47727482, -0.24409588],\n",
      "       [-0.3407577 ,  0.4288172 , -0.83665614, -0.04000443],\n",
      "       [-0.54679327,  0.03189234,  0.24148784,  0.81229651],\n",
      "       [-0.75282884, -0.36503251,  0.11789349, -0.5281962 ]]))\n"
     ]
    }
   ],
   "source": [
    "#Here eig() returns 2 arrays. The first is eigenvalues and the second the corresponding eigenvectors\n",
    "print(linalg.eig(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the condition number of a matrix gives us a way to measure the numerical stability or instability it contributes to computations it is involved in. Condition number is dependant ona choice of norm. A standard choice is the Frobenious norm which is the square root of the sum of the squares of the matirx entries. Under this norm the condition number has the simple form. $$\\kappa(A) = \\frac{\\sigma_{max}(A)}{\\sigma_{min}(A)}$$ where $\\sigma_{max}(A)$ and $\\sigma_{min}(A)$ are the largest and smallest singular values of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.451119230344645\n"
     ]
    }
   ],
   "source": [
    "#We can compute the condition number relative to the Frobenious norm\n",
    "print(linalg.expm_cond(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linalg submodule in scipy also has a large number of matrix functions we can apply. This is again something that is not widely avalible in numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute matrix powers using fractional_matrix_power(). This method is present in numpy too, however you can only raise matrices to integer powers in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.03676910e+07 1.52690050e+08 2.45012410e+08 3.37334770e+08]\n",
      " [1.52690050e+08 3.86204539e+08 6.19719026e+08 8.53233514e+08]\n",
      " [2.45012410e+08 6.19719026e+08 9.94425643e+08 1.36913226e+09]\n",
      " [3.37334770e+08 8.53233514e+08 1.36913226e+09 1.88503100e+09]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.fractional_matrix_power(mnGoodMatrix,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.5695492   2.18810942  2.80666964  3.42522986]\n",
      " [ 2.18810942  5.60915274  7.03019607  9.45123939]\n",
      " [ 2.80666964  7.03019607 12.25372249 15.47724891]\n",
      " [ 3.42522986  9.45123939 15.47724891 22.50325844]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.fractional_matrix_power(mnGoodMatrix,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.71828183 0.         0.        ]\n",
      " [0.         2.71828183 0.        ]\n",
      " [0.         0.         2.71828183]]\n"
     ]
    }
   ],
   "source": [
    "#The matrix exponential\n",
    "print(linalg.expm(mnIden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.26853386 0.9253877  0.58224154 0.23909537]\n",
      " [0.9253877  1.15494559 1.38450348 1.61406137]\n",
      " [0.58224154 1.38450348 2.18676542 2.98902736]\n",
      " [0.23909537 1.61406137 2.98902736 4.36399335]]\n"
     ]
    }
   ],
   "source": [
    "#The matrix log\n",
    "print(linalg.logm(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.32659599 -0.65325955 -0.13845213  0.37635528]\n",
      " [-0.65325955  0.38418388 -0.26131465 -0.0653422 ]\n",
      " [-0.13845213 -0.26131465  0.45729382 -0.50703968]\n",
      " [ 0.37635528 -0.0653422  -0.50703968 -0.10726618]]\n"
     ]
    }
   ],
   "source": [
    "#There are all the standard matrix trig and hyperbolic trig functions in scipy, here is sine\n",
    "print(linalg.sinm(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Decompositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scipy linalg submodule contains a large number of matrix decompsitions. A small subset of these decompostions are contained in numpy, but there is nothing unique to numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LU decompositon of $A$ is a factorization of the matrix into a lower and upper triangular matrices $L$ and $U$. $$A = LU$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.]]), array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.20666667,  1.        ,  0.        ,  0.        ],\n",
      "       [ 0.46666667,  0.36512668,  1.        ,  0.        ],\n",
      "       [ 0.73333333,  0.23845007, -0.32199118,  1.        ]]), array([[150.        , 382.        , 614.        , 847.        ],\n",
      "       [  0.        ,  -8.94666667, -16.89333333, -25.04666667],\n",
      "       [  0.        ,   0.        ,  -2.36512668,  -4.12146051],\n",
      "       [  0.        ,   0.        ,   0.        ,  -2.48802773]]))\n"
     ]
    }
   ],
   "source": [
    "#LU decomposition \n",
    "print(linalg.lu(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The singular value decomposition or SVD of a $m \\times n$ matrix A is a factorization of $A$ in the form\n",
    "$$A = U \\Sigma V^*$$\n",
    "where U is an $m \\times m$ unitary matrix, $\\Sigma$ is an $m \\times n$ rectangular diagonal matrix, and $V$ is a $n \\times n$ unitary matrix. In the case that $A$ is real the matrices $U$ and $V$ are orthogonal. The elements onthe diagonal of $\\Sigma$ are referred to as the singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.13472212, -0.82574206,  0.26062519, -0.48174112],\n",
      "       [-0.3407577 , -0.4288172 ,  0.01156838,  0.83658005],\n",
      "       [-0.54679327, -0.03189234, -0.80501233, -0.22793672],\n",
      "       [-0.75282884,  0.36503251,  0.53281876, -0.1269022 ]]), array([1.49270962e+03, 5.29037925e+00, 1.00000000e+00, 1.00000000e+00]), array([[-0.13472212, -0.3407577 , -0.54679327, -0.75282884],\n",
      "       [-0.82574206, -0.4288172 , -0.03189234,  0.36503251],\n",
      "       [ 0.26062519,  0.01156838, -0.80501233,  0.53281876],\n",
      "       [-0.48174112,  0.83658005, -0.22793672, -0.1269022 ]]))\n"
     ]
    }
   ],
   "source": [
    "#The SVD\n",
    "print(linalg.svd(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.49270962e+03 5.29037925e+00 1.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#We can just return the singular values if we like\n",
    "print(linalg.svdvals(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the range of a matrix $A$ is the space generated by the span of the columns of $A$ were as the null space is the space of all solutions to the equations $$Ax = 0$$. These spaces are fundamental and thus having a basis for them is always handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.13472212 -0.82574206  0.26062519 -0.48174112]\n",
      " [-0.3407577  -0.4288172   0.01156838  0.83658005]\n",
      " [-0.54679327 -0.03189234 -0.80501233 -0.22793672]\n",
      " [-0.75282884  0.36503251  0.53281876 -0.1269022 ]]\n"
     ]
    }
   ],
   "source": [
    "#An orthonormal basis for the range\n",
    "print(linalg.orth(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5427818   0.0734024 ]\n",
      " [-0.66899815 -0.50243554]\n",
      " [-0.29034911  0.78466387]\n",
      " [ 0.41656546 -0.35563073]]\n"
     ]
    }
   ],
   "source": [
    "#An orthonormal basis for the null space\n",
    "print(linalg.null_space(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a positive definite matrix $A$ the Cholesky decomposition is a factorization of the matrix into a lower triangular matrix and it's conjugate transpose. $$A = LL^*$$\n",
    "This factorization is unique and is sometimes referred to as a way to take a square root of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.56776436 12.57237114 19.75658322 26.9407953 ]\n",
      " [ 0.          4.11527446  7.19585134 10.51942538]\n",
      " [ 0.          0.          2.21294891  2.73197193]\n",
      " [ 0.          0.          0.          1.75258879]]\n"
     ]
    }
   ],
   "source": [
    "#The Cholesky decomposition\n",
    "#An orthonormal basis for the range\n",
    "print(linalg.cholesky(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polar decomposition is a factorization of any square matrix $A$ which give the form\n",
    "$$A = UP$$\n",
    "where $U$ is unitray and $P$ is is a semi-positive definite Hermitian matrix. Thus $A$ is relized as a rotation and a scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.00000000e+00,  2.02268757e-14, -2.38420395e-14,\n",
      "         8.54871729e-15],\n",
      "       [-1.96370697e-14,  1.00000000e+00,  1.67921232e-14,\n",
      "        -8.27116153e-15],\n",
      "       [ 2.39253062e-14, -1.64313008e-14,  1.00000000e+00,\n",
      "         3.42087469e-15],\n",
      "       [-8.46545056e-15,  8.54871729e-15, -3.24393290e-15,\n",
      "         1.00000000e+00]]), array([[ 31.,  70., 110., 150.],\n",
      "       [ 70., 175., 278., 382.],\n",
      "       [110., 278., 447., 614.],\n",
      "       [150., 382., 614., 847.]]))\n"
     ]
    }
   ],
   "source": [
    "#The polar decomposition\n",
    "print(linalg.polar(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QR decomposition is a factorization of any matrix $A$ which gives the form\n",
    "$$A = QR$$\n",
    "where $Q$ is orthogonal and $R$ is upper triangular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.15411446,  0.926988  , -0.22306249,  0.2592009 ],\n",
      "       [-0.34800039,  0.2196275 ,  0.88074011, -0.23442771],\n",
      "       [-0.54685776,  0.01323917, -0.41316499, -0.72805632],\n",
      "       [-0.74571513, -0.30377908, -0.06192481,  0.58973938]]), array([[ -201.14919836,  -508.57771662,  -816.01120631, -1123.444696  ],\n",
      "       [    0.        ,    -9.03914606,   -17.57731995,   -26.22612375],\n",
      "       [    0.        ,     0.        ,    -2.39770769,    -3.1502701 ],\n",
      "       [    0.        ,     0.        ,     0.        ,     1.81142431]]))\n"
     ]
    }
   ],
   "source": [
    "#The QR decomposition\n",
    "print(linalg.qr(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Schur decomposition of any matrix $A$ is written\n",
    "$$A = QUQ^{-1}$$\n",
    "where $Q$ is unitary and $U$ is upper triangular. Thus $A$ can be expressed by a unitarily equivalent matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.49270962e+03, -1.90680804e-14, -1.00684644e-14,\n",
      "        -1.68894760e-13],\n",
      "       [ 0.00000000e+00,  5.29037925e+00,  3.19487163e-14,\n",
      "        -2.76313947e-15],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "         1.91094572e-15],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00000000e+00]]), array([[-0.13472212,  0.82574206,  0.47727482, -0.26871686],\n",
      "       [-0.3407577 ,  0.4288172 , -0.83665614,  0.0025495 ],\n",
      "       [-0.54679327,  0.03189234,  0.24148784,  0.80105157],\n",
      "       [-0.75282884, -0.36503251,  0.11789349, -0.53488422]]))\n"
     ]
    }
   ],
   "source": [
    "#The Schur decomposition\n",
    "print(linalg.schur(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hessenberg matrix is a square matrix which is almost triangular. It has one subdiagonal which is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.10000000e+01 -1.98746069e+02 -3.43995474e-14 -3.24941613e-14]\n",
      " [-1.98746069e+02  1.46554177e+03  1.46845360e+01  1.49142147e-13]\n",
      " [ 0.00000000e+00  1.46845360e+01  2.45822785e+00 -2.40918396e-14]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.98203978e-14  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#The Hessenberg form\n",
    "print(linalg.hessenberg(mnGoodMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy has the ability to generate a number of standard matrix structures which are used in many areas in science. We will mentions a number of these structures which play a role in various parts of quantitative finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 7 4]\n",
      " [4 1 7]\n",
      " [7 4 1]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.circulant([1,4,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4. -7. 11. -2.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.companion([1,4,7,-11,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1  1]\n",
      " [ 1 -1  1 -1]\n",
      " [ 1  1 -1 -1]\n",
      " [ 1 -1 -1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.hadamard(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   4   7 -11   2]\n",
      " [  4   7 -11   2   0]\n",
      " [  7 -11   2   0   0]\n",
      " [-11   2   0   0   0]\n",
      " [  2   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.hankel([1,4,7,-11,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   4   7 -11   2   8]\n",
      " [  4   7 -11   2   8   6]\n",
      " [  7 -11   2   8   6   3]\n",
      " [-11   2   8   6   3   9]\n",
      " [  2   8   6   3   9   1]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.hankel([1,4,7,-11,2],[2,8,6,3,9,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   4   7 -11   2]\n",
      " [  4   1   4   7 -11]\n",
      " [  7   4   1   4   7]\n",
      " [-11   7   4   1   4]\n",
      " [  2 -11   7   4   1]]\n"
     ]
    }
   ],
   "source": [
    "print(linalg.toeplitz([1,4,7,-11,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas module is specially crafted for data manipulation and analysis. It provides tools and structures which allow for the fast and easy manipulation of tabular and time series data. This module pairs well with the tools and structures in numpy and scipy. In addition matplotlib can be leveraged on top of all of these modules to provide good visual tools for presentation and analysis. An interesting historical side note is that Pandas was developed by quants out of the need for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary structures in Pandas are series and data frame. A series is a one-dimensional array like structure whos values are index by some kind of label.A DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type. Pandas can handle a wide array of data formats including csv, json, SQL, and Excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [1.34,1.25,1.97,2.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.34, 1.25, 1.97, 2.08]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.97"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.34\n",
       "1    1.25\n",
       "2    1.97\n",
       "3    2.08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series = pd.Series([1.34,1.25,1.97,2.08])\n",
    "price_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.97"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a time series of prices. The series structure (notice the capitalization when you call it) shows that our price are currently indexed by integers. This make the current structure very similar to a list. We can change the indices by passing and index option when we create the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    1.34\n",
       "2020/9/2    1.25\n",
       "2020/9/3    1.97\n",
       "2020/9/4    2.08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series = pd.Series([1.34,1.25,1.97,2.08], index=[\"2020/9/1\", \"2020/9/2\", \"2020/9/3\",\"2020/9/4\"])\n",
    "price_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.97"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series[\"2020/9/3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do this is to pass series a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    1.34\n",
       "2020/9/2    1.25\n",
       "2020/9/3    1.97\n",
       "2020/9/4    2.08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series = pd.Series({\"2020/9/1\":1.34,\"2020/9/2\":1.25,\"2020/9/3\":1.97,\"2020/9/4\":2.08})\n",
    "price_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important aspect of series is that they will handle missing values. In order to take advantage of this series must be passed a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    1.34\n",
       "2020/9/2    1.25\n",
       "2020/9/3    1.97\n",
       "2020/9/4    2.08\n",
       "2020/9/5     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series = pd.Series({\"2020/9/1\":1.34,\"2020/9/2\":1.25,\"2020/9/3\":1.97,\"2020/9/4\":2.08}, index=[\"2020/9/1\", \"2020/9/2\", \"2020/9/3\",\"2020/9/4\",\"2020/9/5\"])\n",
    "price_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    1.34\n",
       "2020/9/2    1.25\n",
       "2020/9/3    1.97\n",
       "2020/9/4    2.08\n",
       "2020/9/5    2.01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_series[\"2020/9/5\"] = 2.01\n",
    "price_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy and scipy functions and methods can be used on series object. When this is done only the values of the series will change, not the values of the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    0.850151\n",
       "2020/9/2    0.810930\n",
       "2020/9/3    1.088562\n",
       "2020/9/4    1.124930\n",
       "2020/9/5    1.101940\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1 + price_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing you must always consider when working with financial data is maintaining alignment. The series() object will use index values to maintain the alignment of two series when doing operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1   -0.148500\n",
       "2020/9/2    0.220741\n",
       "2020/9/3    0.090754\n",
       "2020/9/4    0.075107\n",
       "2020/9/5   -0.655851\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_series = pd.Series({\"2020/9/1\":-.134,\"2020/9/2\":0.25,\"2020/9/3\":0.097,\"2020/9/4\":0.08,\"2020/9/5\":-0.48})\n",
    "risk_free_series = pd.Series({\"2020/9/1\":0.004,\"2020/9/2\":0.003,\"2020/9/3\":0.002,\"2020/9/4\":0.002,\"2020/9/5\":0.001})\n",
    "adjlogreturn_series = np.log(1 + return_series - risk_free_series)\n",
    "adjlogreturn_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame object has a tabular format. It's structure is amenable to a wider array of applications and data types. We can use a data frame to store a collection of time series. Just like a series if we choose not to include an index data frame will use 0, 1, 2, 3, ... by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020/9/1</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020/9/2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020/9/3</th>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL   IBM  MSFT\n",
       "2020/9/1  0.36  0.04  0.12\n",
       "2020/9/2  0.05  0.03  0.01\n",
       "2020/9/3 -0.26 -0.02 -0.34"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbReturns = pd.DataFrame({\"AAPL\":[0.36,0.05,-0.26],\"IBM\":[0.04,0.03,-0.02],\"MSFT\":[0.12,0.01,-0.34]}\n",
    "                         ,index=[\"2020/9/1\", \"2020/9/2\", \"2020/9/3\"])\n",
    "dbReturns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should think of the columns of a data frame as a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    0.36\n",
       "2020/9/2    0.05\n",
       "2020/9/3   -0.26\n",
       "Name: AAPL, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbReturns[\"AAPL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020/9/1    0.36\n",
       "2020/9/2    0.05\n",
       "2020/9/3   -0.26\n",
       "Name: AAPL, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbReturns.AAPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for rows, but you need to access then with the loc() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL    0.36\n",
       "IBM     0.04\n",
       "MSFT    0.12\n",
       "Name: 2020/9/1, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbReturns.loc[\"2020/9/1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the data in a data frame as a array so that we can use the tools in the numpy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36,  0.04,  0.12],\n",
       "       [ 0.05,  0.03,  0.01],\n",
       "       [-0.26, -0.02, -0.34]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbReturns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier pandas can handle a large collection of data types. All of them can be loaded into data frames. There are methods for each type of data you wish to load into a data frame. read_csv() handles csv files, read_json json file, and read_excel excel files. There are many many more type. See I/O API documentation for all the types avalible and their corosponding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_return_series = pd.read_csv(\"/Users/michael/Desktop/FQS_Priority/Invested_Funds/RIEF/IndexReturns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GSPC</th>\n",
       "      <th>RUT</th>\n",
       "      <th>N225</th>\n",
       "      <th>ETZD.PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>-0.005649</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      GSPC       RUT      N225   ETZD.PA\n",
       "0     2017-01-01  0.000000  0.000000  0.000000  0.000000\n",
       "1     2017-01-02  0.000000  0.000000  0.000000  0.000000\n",
       "2     2017-01-03  0.000000  0.000000  0.000000  0.003145\n",
       "3     2017-01-04  0.005722  0.016448  0.000000 -0.000884\n",
       "4     2017-01-05 -0.000771 -0.011535 -0.003750  0.001771\n",
       "...          ...       ...       ...       ...       ...\n",
       "1265  2020-06-19 -0.005649 -0.006095  0.005517  0.005777\n",
       "1266  2020-06-20  0.000000  0.000000  0.000000  0.000000\n",
       "1267  2020-06-21  0.000000  0.000000  0.000000  0.000000\n",
       "1268  2020-06-22  0.000000  0.000000 -0.001847  0.000000\n",
       "1269  2020-06-23  0.000000  0.000000  0.000000  0.000000\n",
       "\n",
       "[1270 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2017-01-01', 0.0, 0.0, 0.0, 0.0],\n",
       "       ['2017-01-02', 0.0, 0.0, 0.0, 0.0],\n",
       "       ['2017-01-03', 0.0, 0.0, 0.0, 0.003144977],\n",
       "       ...,\n",
       "       ['2020-06-21', 0.0, 0.0, 0.0, 0.0],\n",
       "       ['2020-06-22', 0.0, 0.0, -0.0018470539999999999, 0.0],\n",
       "       ['2020-06-23', 0.0, 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a large data frame like this the head method is useful to get an idea of what you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GSPC</th>\n",
       "      <th>RUT</th>\n",
       "      <th>N225</th>\n",
       "      <th>ETZD.PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>-0.00375</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      GSPC       RUT     N225   ETZD.PA\n",
       "0  2017-01-01  0.000000  0.000000  0.00000  0.000000\n",
       "1  2017-01-02  0.000000  0.000000  0.00000  0.000000\n",
       "2  2017-01-03  0.000000  0.000000  0.00000  0.003145\n",
       "3  2017-01-04  0.005722  0.016448  0.00000 -0.000884\n",
       "4  2017-01-05 -0.000771 -0.011535 -0.00375  0.001771"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to have to reindex this. Since the index for the data frame is an attribute we can access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1270, step=1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2017-01-01\n",
       "1       2017-01-02\n",
       "2       2017-01-03\n",
       "3       2017-01-04\n",
       "4       2017-01-05\n",
       "           ...    \n",
       "1265    2020-06-19\n",
       "1266    2020-06-20\n",
       "1267    2020-06-21\n",
       "1268    2020-06-22\n",
       "1269    2020-06-23\n",
       "Name: Unnamed: 0, Length: 1270, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(index_return_series[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-01-01',\n",
       " '2017-01-02',\n",
       " '2017-01-03',\n",
       " '2017-01-04',\n",
       " '2017-01-05',\n",
       " '2017-01-06',\n",
       " '2017-01-07',\n",
       " '2017-01-08',\n",
       " '2017-01-09',\n",
       " '2017-01-10',\n",
       " '2017-01-11',\n",
       " '2017-01-12',\n",
       " '2017-01-13',\n",
       " '2017-01-14',\n",
       " '2017-01-15',\n",
       " '2017-01-16',\n",
       " '2017-01-17',\n",
       " '2017-01-18',\n",
       " '2017-01-19',\n",
       " '2017-01-20',\n",
       " '2017-01-21',\n",
       " '2017-01-22',\n",
       " '2017-01-23',\n",
       " '2017-01-24',\n",
       " '2017-01-25',\n",
       " '2017-01-26',\n",
       " '2017-01-27',\n",
       " '2017-01-28',\n",
       " '2017-01-29',\n",
       " '2017-01-30',\n",
       " '2017-01-31',\n",
       " '2017-02-01',\n",
       " '2017-02-02',\n",
       " '2017-02-03',\n",
       " '2017-02-04',\n",
       " '2017-02-05',\n",
       " '2017-02-06',\n",
       " '2017-02-07',\n",
       " '2017-02-08',\n",
       " '2017-02-09',\n",
       " '2017-02-10',\n",
       " '2017-02-11',\n",
       " '2017-02-12',\n",
       " '2017-02-13',\n",
       " '2017-02-14',\n",
       " '2017-02-15',\n",
       " '2017-02-16',\n",
       " '2017-02-17',\n",
       " '2017-02-18',\n",
       " '2017-02-19',\n",
       " '2017-02-20',\n",
       " '2017-02-21',\n",
       " '2017-02-22',\n",
       " '2017-02-23',\n",
       " '2017-02-24',\n",
       " '2017-02-25',\n",
       " '2017-02-26',\n",
       " '2017-02-27',\n",
       " '2017-02-28',\n",
       " '2017-03-01',\n",
       " '2017-03-02',\n",
       " '2017-03-03',\n",
       " '2017-03-04',\n",
       " '2017-03-05',\n",
       " '2017-03-06',\n",
       " '2017-03-07',\n",
       " '2017-03-08',\n",
       " '2017-03-09',\n",
       " '2017-03-10',\n",
       " '2017-03-11',\n",
       " '2017-03-12',\n",
       " '2017-03-13',\n",
       " '2017-03-14',\n",
       " '2017-03-15',\n",
       " '2017-03-16',\n",
       " '2017-03-17',\n",
       " '2017-03-18',\n",
       " '2017-03-19',\n",
       " '2017-03-20',\n",
       " '2017-03-21',\n",
       " '2017-03-22',\n",
       " '2017-03-23',\n",
       " '2017-03-24',\n",
       " '2017-03-25',\n",
       " '2017-03-26',\n",
       " '2017-03-27',\n",
       " '2017-03-28',\n",
       " '2017-03-29',\n",
       " '2017-03-30',\n",
       " '2017-03-31',\n",
       " '2017-04-01',\n",
       " '2017-04-02',\n",
       " '2017-04-03',\n",
       " '2017-04-04',\n",
       " '2017-04-05',\n",
       " '2017-04-06',\n",
       " '2017-04-07',\n",
       " '2017-04-08',\n",
       " '2017-04-09',\n",
       " '2017-04-10',\n",
       " '2017-04-11',\n",
       " '2017-04-12',\n",
       " '2017-04-13',\n",
       " '2017-04-14',\n",
       " '2017-04-15',\n",
       " '2017-04-16',\n",
       " '2017-04-17',\n",
       " '2017-04-18',\n",
       " '2017-04-19',\n",
       " '2017-04-20',\n",
       " '2017-04-21',\n",
       " '2017-04-22',\n",
       " '2017-04-23',\n",
       " '2017-04-24',\n",
       " '2017-04-25',\n",
       " '2017-04-26',\n",
       " '2017-04-27',\n",
       " '2017-04-28',\n",
       " '2017-04-29',\n",
       " '2017-04-30',\n",
       " '2017-05-01',\n",
       " '2017-05-02',\n",
       " '2017-05-03',\n",
       " '2017-05-04',\n",
       " '2017-05-05',\n",
       " '2017-05-06',\n",
       " '2017-05-07',\n",
       " '2017-05-08',\n",
       " '2017-05-09',\n",
       " '2017-05-10',\n",
       " '2017-05-11',\n",
       " '2017-05-12',\n",
       " '2017-05-13',\n",
       " '2017-05-14',\n",
       " '2017-05-15',\n",
       " '2017-05-16',\n",
       " '2017-05-17',\n",
       " '2017-05-18',\n",
       " '2017-05-19',\n",
       " '2017-05-20',\n",
       " '2017-05-21',\n",
       " '2017-05-22',\n",
       " '2017-05-23',\n",
       " '2017-05-24',\n",
       " '2017-05-25',\n",
       " '2017-05-26',\n",
       " '2017-05-27',\n",
       " '2017-05-28',\n",
       " '2017-05-29',\n",
       " '2017-05-30',\n",
       " '2017-05-31',\n",
       " '2017-06-01',\n",
       " '2017-06-02',\n",
       " '2017-06-03',\n",
       " '2017-06-04',\n",
       " '2017-06-05',\n",
       " '2017-06-06',\n",
       " '2017-06-07',\n",
       " '2017-06-08',\n",
       " '2017-06-09',\n",
       " '2017-06-10',\n",
       " '2017-06-11',\n",
       " '2017-06-12',\n",
       " '2017-06-13',\n",
       " '2017-06-14',\n",
       " '2017-06-15',\n",
       " '2017-06-16',\n",
       " '2017-06-17',\n",
       " '2017-06-18',\n",
       " '2017-06-19',\n",
       " '2017-06-20',\n",
       " '2017-06-21',\n",
       " '2017-06-22',\n",
       " '2017-06-23',\n",
       " '2017-06-24',\n",
       " '2017-06-25',\n",
       " '2017-06-26',\n",
       " '2017-06-27',\n",
       " '2017-06-28',\n",
       " '2017-06-29',\n",
       " '2017-06-30',\n",
       " '2017-07-01',\n",
       " '2017-07-02',\n",
       " '2017-07-03',\n",
       " '2017-07-04',\n",
       " '2017-07-05',\n",
       " '2017-07-06',\n",
       " '2017-07-07',\n",
       " '2017-07-08',\n",
       " '2017-07-09',\n",
       " '2017-07-10',\n",
       " '2017-07-11',\n",
       " '2017-07-12',\n",
       " '2017-07-13',\n",
       " '2017-07-14',\n",
       " '2017-07-15',\n",
       " '2017-07-16',\n",
       " '2017-07-17',\n",
       " '2017-07-18',\n",
       " '2017-07-19',\n",
       " '2017-07-20',\n",
       " '2017-07-21',\n",
       " '2017-07-22',\n",
       " '2017-07-23',\n",
       " '2017-07-24',\n",
       " '2017-07-25',\n",
       " '2017-07-26',\n",
       " '2017-07-27',\n",
       " '2017-07-28',\n",
       " '2017-07-29',\n",
       " '2017-07-30',\n",
       " '2017-07-31',\n",
       " '2017-08-01',\n",
       " '2017-08-02',\n",
       " '2017-08-03',\n",
       " '2017-08-04',\n",
       " '2017-08-05',\n",
       " '2017-08-06',\n",
       " '2017-08-07',\n",
       " '2017-08-08',\n",
       " '2017-08-09',\n",
       " '2017-08-10',\n",
       " '2017-08-11',\n",
       " '2017-08-12',\n",
       " '2017-08-13',\n",
       " '2017-08-14',\n",
       " '2017-08-15',\n",
       " '2017-08-16',\n",
       " '2017-08-17',\n",
       " '2017-08-18',\n",
       " '2017-08-19',\n",
       " '2017-08-20',\n",
       " '2017-08-21',\n",
       " '2017-08-22',\n",
       " '2017-08-23',\n",
       " '2017-08-24',\n",
       " '2017-08-25',\n",
       " '2017-08-26',\n",
       " '2017-08-27',\n",
       " '2017-08-28',\n",
       " '2017-08-29',\n",
       " '2017-08-30',\n",
       " '2017-08-31',\n",
       " '2017-09-01',\n",
       " '2017-09-02',\n",
       " '2017-09-03',\n",
       " '2017-09-04',\n",
       " '2017-09-05',\n",
       " '2017-09-06',\n",
       " '2017-09-07',\n",
       " '2017-09-08',\n",
       " '2017-09-09',\n",
       " '2017-09-10',\n",
       " '2017-09-11',\n",
       " '2017-09-12',\n",
       " '2017-09-13',\n",
       " '2017-09-14',\n",
       " '2017-09-15',\n",
       " '2017-09-16',\n",
       " '2017-09-17',\n",
       " '2017-09-18',\n",
       " '2017-09-19',\n",
       " '2017-09-20',\n",
       " '2017-09-21',\n",
       " '2017-09-22',\n",
       " '2017-09-23',\n",
       " '2017-09-24',\n",
       " '2017-09-25',\n",
       " '2017-09-26',\n",
       " '2017-09-27',\n",
       " '2017-09-28',\n",
       " '2017-09-29',\n",
       " '2017-09-30',\n",
       " '2017-10-01',\n",
       " '2017-10-02',\n",
       " '2017-10-03',\n",
       " '2017-10-04',\n",
       " '2017-10-05',\n",
       " '2017-10-06',\n",
       " '2017-10-07',\n",
       " '2017-10-08',\n",
       " '2017-10-09',\n",
       " '2017-10-10',\n",
       " '2017-10-11',\n",
       " '2017-10-12',\n",
       " '2017-10-13',\n",
       " '2017-10-14',\n",
       " '2017-10-15',\n",
       " '2017-10-16',\n",
       " '2017-10-17',\n",
       " '2017-10-18',\n",
       " '2017-10-19',\n",
       " '2017-10-20',\n",
       " '2017-10-21',\n",
       " '2017-10-22',\n",
       " '2017-10-23',\n",
       " '2017-10-24',\n",
       " '2017-10-25',\n",
       " '2017-10-26',\n",
       " '2017-10-27',\n",
       " '2017-10-28',\n",
       " '2017-10-29',\n",
       " '2017-10-30',\n",
       " '2017-10-31',\n",
       " '2017-11-01',\n",
       " '2017-11-02',\n",
       " '2017-11-03',\n",
       " '2017-11-04',\n",
       " '2017-11-05',\n",
       " '2017-11-06',\n",
       " '2017-11-07',\n",
       " '2017-11-08',\n",
       " '2017-11-09',\n",
       " '2017-11-10',\n",
       " '2017-11-11',\n",
       " '2017-11-12',\n",
       " '2017-11-13',\n",
       " '2017-11-14',\n",
       " '2017-11-15',\n",
       " '2017-11-16',\n",
       " '2017-11-17',\n",
       " '2017-11-18',\n",
       " '2017-11-19',\n",
       " '2017-11-20',\n",
       " '2017-11-21',\n",
       " '2017-11-22',\n",
       " '2017-11-23',\n",
       " '2017-11-24',\n",
       " '2017-11-25',\n",
       " '2017-11-26',\n",
       " '2017-11-27',\n",
       " '2017-11-28',\n",
       " '2017-11-29',\n",
       " '2017-11-30',\n",
       " '2017-12-01',\n",
       " '2017-12-02',\n",
       " '2017-12-03',\n",
       " '2017-12-04',\n",
       " '2017-12-05',\n",
       " '2017-12-06',\n",
       " '2017-12-07',\n",
       " '2017-12-08',\n",
       " '2017-12-09',\n",
       " '2017-12-10',\n",
       " '2017-12-11',\n",
       " '2017-12-12',\n",
       " '2017-12-13',\n",
       " '2017-12-14',\n",
       " '2017-12-15',\n",
       " '2017-12-16',\n",
       " '2017-12-17',\n",
       " '2017-12-18',\n",
       " '2017-12-19',\n",
       " '2017-12-20',\n",
       " '2017-12-21',\n",
       " '2017-12-22',\n",
       " '2017-12-23',\n",
       " '2017-12-24',\n",
       " '2017-12-25',\n",
       " '2017-12-26',\n",
       " '2017-12-27',\n",
       " '2017-12-28',\n",
       " '2017-12-29',\n",
       " '2017-12-30',\n",
       " '2017-12-31',\n",
       " '2018-01-01',\n",
       " '2018-01-02',\n",
       " '2018-01-03',\n",
       " '2018-01-04',\n",
       " '2018-01-05',\n",
       " '2018-01-06',\n",
       " '2018-01-07',\n",
       " '2018-01-08',\n",
       " '2018-01-09',\n",
       " '2018-01-10',\n",
       " '2018-01-11',\n",
       " '2018-01-12',\n",
       " '2018-01-13',\n",
       " '2018-01-14',\n",
       " '2018-01-15',\n",
       " '2018-01-16',\n",
       " '2018-01-17',\n",
       " '2018-01-18',\n",
       " '2018-01-19',\n",
       " '2018-01-20',\n",
       " '2018-01-21',\n",
       " '2018-01-22',\n",
       " '2018-01-23',\n",
       " '2018-01-24',\n",
       " '2018-01-25',\n",
       " '2018-01-26',\n",
       " '2018-01-27',\n",
       " '2018-01-28',\n",
       " '2018-01-29',\n",
       " '2018-01-30',\n",
       " '2018-01-31',\n",
       " '2018-02-01',\n",
       " '2018-02-02',\n",
       " '2018-02-03',\n",
       " '2018-02-04',\n",
       " '2018-02-05',\n",
       " '2018-02-06',\n",
       " '2018-02-07',\n",
       " '2018-02-08',\n",
       " '2018-02-09',\n",
       " '2018-02-10',\n",
       " '2018-02-11',\n",
       " '2018-02-12',\n",
       " '2018-02-13',\n",
       " '2018-02-14',\n",
       " '2018-02-15',\n",
       " '2018-02-16',\n",
       " '2018-02-17',\n",
       " '2018-02-18',\n",
       " '2018-02-19',\n",
       " '2018-02-20',\n",
       " '2018-02-21',\n",
       " '2018-02-22',\n",
       " '2018-02-23',\n",
       " '2018-02-24',\n",
       " '2018-02-25',\n",
       " '2018-02-26',\n",
       " '2018-02-27',\n",
       " '2018-02-28',\n",
       " '2018-03-01',\n",
       " '2018-03-02',\n",
       " '2018-03-03',\n",
       " '2018-03-04',\n",
       " '2018-03-05',\n",
       " '2018-03-06',\n",
       " '2018-03-07',\n",
       " '2018-03-08',\n",
       " '2018-03-09',\n",
       " '2018-03-10',\n",
       " '2018-03-11',\n",
       " '2018-03-12',\n",
       " '2018-03-13',\n",
       " '2018-03-14',\n",
       " '2018-03-15',\n",
       " '2018-03-16',\n",
       " '2018-03-17',\n",
       " '2018-03-18',\n",
       " '2018-03-19',\n",
       " '2018-03-20',\n",
       " '2018-03-21',\n",
       " '2018-03-22',\n",
       " '2018-03-23',\n",
       " '2018-03-24',\n",
       " '2018-03-25',\n",
       " '2018-03-26',\n",
       " '2018-03-27',\n",
       " '2018-03-28',\n",
       " '2018-03-29',\n",
       " '2018-03-30',\n",
       " '2018-03-31',\n",
       " '2018-04-01',\n",
       " '2018-04-02',\n",
       " '2018-04-03',\n",
       " '2018-04-04',\n",
       " '2018-04-05',\n",
       " '2018-04-06',\n",
       " '2018-04-07',\n",
       " '2018-04-08',\n",
       " '2018-04-09',\n",
       " '2018-04-10',\n",
       " '2018-04-11',\n",
       " '2018-04-12',\n",
       " '2018-04-13',\n",
       " '2018-04-14',\n",
       " '2018-04-15',\n",
       " '2018-04-16',\n",
       " '2018-04-17',\n",
       " '2018-04-18',\n",
       " '2018-04-19',\n",
       " '2018-04-20',\n",
       " '2018-04-21',\n",
       " '2018-04-22',\n",
       " '2018-04-23',\n",
       " '2018-04-24',\n",
       " '2018-04-25',\n",
       " '2018-04-26',\n",
       " '2018-04-27',\n",
       " '2018-04-28',\n",
       " '2018-04-29',\n",
       " '2018-04-30',\n",
       " '2018-05-01',\n",
       " '2018-05-02',\n",
       " '2018-05-03',\n",
       " '2018-05-04',\n",
       " '2018-05-05',\n",
       " '2018-05-06',\n",
       " '2018-05-07',\n",
       " '2018-05-08',\n",
       " '2018-05-09',\n",
       " '2018-05-10',\n",
       " '2018-05-11',\n",
       " '2018-05-12',\n",
       " '2018-05-13',\n",
       " '2018-05-14',\n",
       " '2018-05-15',\n",
       " '2018-05-16',\n",
       " '2018-05-17',\n",
       " '2018-05-18',\n",
       " '2018-05-19',\n",
       " '2018-05-20',\n",
       " '2018-05-21',\n",
       " '2018-05-22',\n",
       " '2018-05-23',\n",
       " '2018-05-24',\n",
       " '2018-05-25',\n",
       " '2018-05-26',\n",
       " '2018-05-27',\n",
       " '2018-05-28',\n",
       " '2018-05-29',\n",
       " '2018-05-30',\n",
       " '2018-05-31',\n",
       " '2018-06-01',\n",
       " '2018-06-02',\n",
       " '2018-06-03',\n",
       " '2018-06-04',\n",
       " '2018-06-05',\n",
       " '2018-06-06',\n",
       " '2018-06-07',\n",
       " '2018-06-08',\n",
       " '2018-06-09',\n",
       " '2018-06-10',\n",
       " '2018-06-11',\n",
       " '2018-06-12',\n",
       " '2018-06-13',\n",
       " '2018-06-14',\n",
       " '2018-06-15',\n",
       " '2018-06-16',\n",
       " '2018-06-17',\n",
       " '2018-06-18',\n",
       " '2018-06-19',\n",
       " '2018-06-20',\n",
       " '2018-06-21',\n",
       " '2018-06-22',\n",
       " '2018-06-23',\n",
       " '2018-06-24',\n",
       " '2018-06-25',\n",
       " '2018-06-26',\n",
       " '2018-06-27',\n",
       " '2018-06-28',\n",
       " '2018-06-29',\n",
       " '2018-06-30',\n",
       " '2018-07-01',\n",
       " '2018-07-02',\n",
       " '2018-07-03',\n",
       " '2018-07-04',\n",
       " '2018-07-05',\n",
       " '2018-07-06',\n",
       " '2018-07-07',\n",
       " '2018-07-08',\n",
       " '2018-07-09',\n",
       " '2018-07-10',\n",
       " '2018-07-11',\n",
       " '2018-07-12',\n",
       " '2018-07-13',\n",
       " '2018-07-14',\n",
       " '2018-07-15',\n",
       " '2018-07-16',\n",
       " '2018-07-17',\n",
       " '2018-07-18',\n",
       " '2018-07-19',\n",
       " '2018-07-20',\n",
       " '2018-07-21',\n",
       " '2018-07-22',\n",
       " '2018-07-23',\n",
       " '2018-07-24',\n",
       " '2018-07-25',\n",
       " '2018-07-26',\n",
       " '2018-07-27',\n",
       " '2018-07-28',\n",
       " '2018-07-29',\n",
       " '2018-07-30',\n",
       " '2018-07-31',\n",
       " '2018-08-01',\n",
       " '2018-08-02',\n",
       " '2018-08-03',\n",
       " '2018-08-04',\n",
       " '2018-08-05',\n",
       " '2018-08-06',\n",
       " '2018-08-07',\n",
       " '2018-08-08',\n",
       " '2018-08-09',\n",
       " '2018-08-10',\n",
       " '2018-08-11',\n",
       " '2018-08-12',\n",
       " '2018-08-13',\n",
       " '2018-08-14',\n",
       " '2018-08-15',\n",
       " '2018-08-16',\n",
       " '2018-08-17',\n",
       " '2018-08-18',\n",
       " '2018-08-19',\n",
       " '2018-08-20',\n",
       " '2018-08-21',\n",
       " '2018-08-22',\n",
       " '2018-08-23',\n",
       " '2018-08-24',\n",
       " '2018-08-25',\n",
       " '2018-08-26',\n",
       " '2018-08-27',\n",
       " '2018-08-28',\n",
       " '2018-08-29',\n",
       " '2018-08-30',\n",
       " '2018-08-31',\n",
       " '2018-09-01',\n",
       " '2018-09-02',\n",
       " '2018-09-03',\n",
       " '2018-09-04',\n",
       " '2018-09-05',\n",
       " '2018-09-06',\n",
       " '2018-09-07',\n",
       " '2018-09-08',\n",
       " '2018-09-09',\n",
       " '2018-09-10',\n",
       " '2018-09-11',\n",
       " '2018-09-12',\n",
       " '2018-09-13',\n",
       " '2018-09-14',\n",
       " '2018-09-15',\n",
       " '2018-09-16',\n",
       " '2018-09-17',\n",
       " '2018-09-18',\n",
       " '2018-09-19',\n",
       " '2018-09-20',\n",
       " '2018-09-21',\n",
       " '2018-09-22',\n",
       " '2018-09-23',\n",
       " '2018-09-24',\n",
       " '2018-09-25',\n",
       " '2018-09-26',\n",
       " '2018-09-27',\n",
       " '2018-09-28',\n",
       " '2018-09-29',\n",
       " '2018-09-30',\n",
       " '2018-10-01',\n",
       " '2018-10-02',\n",
       " '2018-10-03',\n",
       " '2018-10-04',\n",
       " '2018-10-05',\n",
       " '2018-10-06',\n",
       " '2018-10-07',\n",
       " '2018-10-08',\n",
       " '2018-10-09',\n",
       " '2018-10-10',\n",
       " '2018-10-11',\n",
       " '2018-10-12',\n",
       " '2018-10-13',\n",
       " '2018-10-14',\n",
       " '2018-10-15',\n",
       " '2018-10-16',\n",
       " '2018-10-17',\n",
       " '2018-10-18',\n",
       " '2018-10-19',\n",
       " '2018-10-20',\n",
       " '2018-10-21',\n",
       " '2018-10-22',\n",
       " '2018-10-23',\n",
       " '2018-10-24',\n",
       " '2018-10-25',\n",
       " '2018-10-26',\n",
       " '2018-10-27',\n",
       " '2018-10-28',\n",
       " '2018-10-29',\n",
       " '2018-10-30',\n",
       " '2018-10-31',\n",
       " '2018-11-01',\n",
       " '2018-11-02',\n",
       " '2018-11-03',\n",
       " '2018-11-04',\n",
       " '2018-11-05',\n",
       " '2018-11-06',\n",
       " '2018-11-07',\n",
       " '2018-11-08',\n",
       " '2018-11-09',\n",
       " '2018-11-10',\n",
       " '2018-11-11',\n",
       " '2018-11-12',\n",
       " '2018-11-13',\n",
       " '2018-11-14',\n",
       " '2018-11-15',\n",
       " '2018-11-16',\n",
       " '2018-11-17',\n",
       " '2018-11-18',\n",
       " '2018-11-19',\n",
       " '2018-11-20',\n",
       " '2018-11-21',\n",
       " '2018-11-22',\n",
       " '2018-11-23',\n",
       " '2018-11-24',\n",
       " '2018-11-25',\n",
       " '2018-11-26',\n",
       " '2018-11-27',\n",
       " '2018-11-28',\n",
       " '2018-11-29',\n",
       " '2018-11-30',\n",
       " '2018-12-01',\n",
       " '2018-12-02',\n",
       " '2018-12-03',\n",
       " '2018-12-04',\n",
       " '2018-12-05',\n",
       " '2018-12-06',\n",
       " '2018-12-07',\n",
       " '2018-12-08',\n",
       " '2018-12-09',\n",
       " '2018-12-10',\n",
       " '2018-12-11',\n",
       " '2018-12-12',\n",
       " '2018-12-13',\n",
       " '2018-12-14',\n",
       " '2018-12-15',\n",
       " '2018-12-16',\n",
       " '2018-12-17',\n",
       " '2018-12-18',\n",
       " '2018-12-19',\n",
       " '2018-12-20',\n",
       " '2018-12-21',\n",
       " '2018-12-22',\n",
       " '2018-12-23',\n",
       " '2018-12-24',\n",
       " '2018-12-25',\n",
       " '2018-12-26',\n",
       " '2018-12-27',\n",
       " '2018-12-28',\n",
       " '2018-12-29',\n",
       " '2018-12-30',\n",
       " '2018-12-31',\n",
       " '2019-01-01',\n",
       " '2019-01-02',\n",
       " '2019-01-03',\n",
       " '2019-01-04',\n",
       " '2019-01-05',\n",
       " '2019-01-06',\n",
       " '2019-01-07',\n",
       " '2019-01-08',\n",
       " '2019-01-09',\n",
       " '2019-01-10',\n",
       " '2019-01-11',\n",
       " '2019-01-12',\n",
       " '2019-01-13',\n",
       " '2019-01-14',\n",
       " '2019-01-15',\n",
       " '2019-01-16',\n",
       " '2019-01-17',\n",
       " '2019-01-18',\n",
       " '2019-01-19',\n",
       " '2019-01-20',\n",
       " '2019-01-21',\n",
       " '2019-01-22',\n",
       " '2019-01-23',\n",
       " '2019-01-24',\n",
       " '2019-01-25',\n",
       " '2019-01-26',\n",
       " '2019-01-27',\n",
       " '2019-01-28',\n",
       " '2019-01-29',\n",
       " '2019-01-30',\n",
       " '2019-01-31',\n",
       " '2019-02-01',\n",
       " '2019-02-02',\n",
       " '2019-02-03',\n",
       " '2019-02-04',\n",
       " '2019-02-05',\n",
       " '2019-02-06',\n",
       " '2019-02-07',\n",
       " '2019-02-08',\n",
       " '2019-02-09',\n",
       " '2019-02-10',\n",
       " '2019-02-11',\n",
       " '2019-02-12',\n",
       " '2019-02-13',\n",
       " '2019-02-14',\n",
       " '2019-02-15',\n",
       " '2019-02-16',\n",
       " '2019-02-17',\n",
       " '2019-02-18',\n",
       " '2019-02-19',\n",
       " '2019-02-20',\n",
       " '2019-02-21',\n",
       " '2019-02-22',\n",
       " '2019-02-23',\n",
       " '2019-02-24',\n",
       " '2019-02-25',\n",
       " '2019-02-26',\n",
       " '2019-02-27',\n",
       " '2019-02-28',\n",
       " '2019-03-01',\n",
       " '2019-03-02',\n",
       " '2019-03-03',\n",
       " '2019-03-04',\n",
       " '2019-03-05',\n",
       " '2019-03-06',\n",
       " '2019-03-07',\n",
       " '2019-03-08',\n",
       " '2019-03-09',\n",
       " '2019-03-10',\n",
       " '2019-03-11',\n",
       " '2019-03-12',\n",
       " '2019-03-13',\n",
       " '2019-03-14',\n",
       " '2019-03-15',\n",
       " '2019-03-16',\n",
       " '2019-03-17',\n",
       " '2019-03-18',\n",
       " '2019-03-19',\n",
       " '2019-03-20',\n",
       " '2019-03-21',\n",
       " '2019-03-22',\n",
       " '2019-03-23',\n",
       " '2019-03-24',\n",
       " '2019-03-25',\n",
       " '2019-03-26',\n",
       " '2019-03-27',\n",
       " '2019-03-28',\n",
       " '2019-03-29',\n",
       " '2019-03-30',\n",
       " '2019-03-31',\n",
       " '2019-04-01',\n",
       " '2019-04-02',\n",
       " '2019-04-03',\n",
       " '2019-04-04',\n",
       " '2019-04-05',\n",
       " '2019-04-06',\n",
       " '2019-04-07',\n",
       " '2019-04-08',\n",
       " '2019-04-09',\n",
       " '2019-04-10',\n",
       " '2019-04-11',\n",
       " '2019-04-12',\n",
       " '2019-04-13',\n",
       " '2019-04-14',\n",
       " '2019-04-15',\n",
       " '2019-04-16',\n",
       " '2019-04-17',\n",
       " '2019-04-18',\n",
       " '2019-04-19',\n",
       " '2019-04-20',\n",
       " '2019-04-21',\n",
       " '2019-04-22',\n",
       " '2019-04-23',\n",
       " '2019-04-24',\n",
       " '2019-04-25',\n",
       " '2019-04-26',\n",
       " '2019-04-27',\n",
       " '2019-04-28',\n",
       " '2019-04-29',\n",
       " '2019-04-30',\n",
       " '2019-05-01',\n",
       " '2019-05-02',\n",
       " '2019-05-03',\n",
       " '2019-05-04',\n",
       " '2019-05-05',\n",
       " '2019-05-06',\n",
       " '2019-05-07',\n",
       " '2019-05-08',\n",
       " '2019-05-09',\n",
       " '2019-05-10',\n",
       " '2019-05-11',\n",
       " '2019-05-12',\n",
       " '2019-05-13',\n",
       " '2019-05-14',\n",
       " '2019-05-15',\n",
       " '2019-05-16',\n",
       " '2019-05-17',\n",
       " '2019-05-18',\n",
       " '2019-05-19',\n",
       " '2019-05-20',\n",
       " '2019-05-21',\n",
       " '2019-05-22',\n",
       " '2019-05-23',\n",
       " '2019-05-24',\n",
       " '2019-05-25',\n",
       " '2019-05-26',\n",
       " '2019-05-27',\n",
       " '2019-05-28',\n",
       " '2019-05-29',\n",
       " '2019-05-30',\n",
       " '2019-05-31',\n",
       " '2019-06-01',\n",
       " '2019-06-02',\n",
       " '2019-06-03',\n",
       " '2019-06-04',\n",
       " '2019-06-05',\n",
       " '2019-06-06',\n",
       " '2019-06-07',\n",
       " '2019-06-08',\n",
       " '2019-06-09',\n",
       " '2019-06-10',\n",
       " '2019-06-11',\n",
       " '2019-06-12',\n",
       " '2019-06-13',\n",
       " '2019-06-14',\n",
       " '2019-06-15',\n",
       " '2019-06-16',\n",
       " '2019-06-17',\n",
       " '2019-06-18',\n",
       " '2019-06-19',\n",
       " '2019-06-20',\n",
       " '2019-06-21',\n",
       " '2019-06-22',\n",
       " '2019-06-23',\n",
       " '2019-06-24',\n",
       " '2019-06-25',\n",
       " '2019-06-26',\n",
       " '2019-06-27',\n",
       " '2019-06-28',\n",
       " '2019-06-29',\n",
       " '2019-06-30',\n",
       " '2019-07-01',\n",
       " '2019-07-02',\n",
       " '2019-07-03',\n",
       " '2019-07-04',\n",
       " '2019-07-05',\n",
       " '2019-07-06',\n",
       " '2019-07-07',\n",
       " '2019-07-08',\n",
       " '2019-07-09',\n",
       " '2019-07-10',\n",
       " '2019-07-11',\n",
       " '2019-07-12',\n",
       " '2019-07-13',\n",
       " '2019-07-14',\n",
       " '2019-07-15',\n",
       " '2019-07-16',\n",
       " '2019-07-17',\n",
       " '2019-07-18',\n",
       " '2019-07-19',\n",
       " '2019-07-20',\n",
       " '2019-07-21',\n",
       " '2019-07-22',\n",
       " '2019-07-23',\n",
       " '2019-07-24',\n",
       " '2019-07-25',\n",
       " '2019-07-26',\n",
       " '2019-07-27',\n",
       " '2019-07-28',\n",
       " '2019-07-29',\n",
       " '2019-07-30',\n",
       " '2019-07-31',\n",
       " '2019-08-01',\n",
       " '2019-08-02',\n",
       " '2019-08-03',\n",
       " '2019-08-04',\n",
       " '2019-08-05',\n",
       " '2019-08-06',\n",
       " '2019-08-07',\n",
       " '2019-08-08',\n",
       " '2019-08-09',\n",
       " '2019-08-10',\n",
       " '2019-08-11',\n",
       " '2019-08-12',\n",
       " '2019-08-13',\n",
       " '2019-08-14',\n",
       " '2019-08-15',\n",
       " '2019-08-16',\n",
       " '2019-08-17',\n",
       " '2019-08-18',\n",
       " '2019-08-19',\n",
       " '2019-08-20',\n",
       " '2019-08-21',\n",
       " '2019-08-22',\n",
       " '2019-08-23',\n",
       " '2019-08-24',\n",
       " '2019-08-25',\n",
       " '2019-08-26',\n",
       " '2019-08-27',\n",
       " '2019-08-28',\n",
       " '2019-08-29',\n",
       " '2019-08-30',\n",
       " '2019-08-31',\n",
       " '2019-09-01',\n",
       " '2019-09-02',\n",
       " '2019-09-03',\n",
       " '2019-09-04',\n",
       " '2019-09-05',\n",
       " '2019-09-06',\n",
       " '2019-09-07',\n",
       " '2019-09-08',\n",
       " '2019-09-09',\n",
       " '2019-09-10',\n",
       " '2019-09-11',\n",
       " '2019-09-12',\n",
       " '2019-09-13',\n",
       " '2019-09-14',\n",
       " '2019-09-15',\n",
       " '2019-09-16',\n",
       " '2019-09-17',\n",
       " '2019-09-18',\n",
       " '2019-09-19',\n",
       " '2019-09-20',\n",
       " '2019-09-21',\n",
       " '2019-09-22',\n",
       " '2019-09-23',\n",
       " '2019-09-24',\n",
       " '2019-09-25',\n",
       " '2019-09-26',\n",
       " '2019-09-27',\n",
       " ...]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_return_series.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GSPC</th>\n",
       "      <th>RUT</th>\n",
       "      <th>N225</th>\n",
       "      <th>ETZD.PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>-0.005649</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0      GSPC       RUT      N225   ETZD.PA\n",
       "2017-01-01  2017-01-01  0.000000  0.000000  0.000000  0.000000\n",
       "2017-01-02  2017-01-02  0.000000  0.000000  0.000000  0.000000\n",
       "2017-01-03  2017-01-03  0.000000  0.000000  0.000000  0.003145\n",
       "2017-01-04  2017-01-04  0.005722  0.016448  0.000000 -0.000884\n",
       "2017-01-05  2017-01-05 -0.000771 -0.011535 -0.003750  0.001771\n",
       "...                ...       ...       ...       ...       ...\n",
       "2020-06-19  2020-06-19 -0.005649 -0.006095  0.005517  0.005777\n",
       "2020-06-20  2020-06-20  0.000000  0.000000  0.000000  0.000000\n",
       "2020-06-21  2020-06-21  0.000000  0.000000  0.000000  0.000000\n",
       "2020-06-22  2020-06-22  0.000000  0.000000 -0.001847  0.000000\n",
       "2020-06-23  2020-06-23  0.000000  0.000000  0.000000  0.000000\n",
       "\n",
       "[1270 rows x 5 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "del index_return_series[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSPC</th>\n",
       "      <th>RUT</th>\n",
       "      <th>N225</th>\n",
       "      <th>ETZD.PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>-0.005649</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GSPC       RUT      N225   ETZD.PA\n",
       "2017-01-01  0.000000  0.000000  0.000000  0.000000\n",
       "2017-01-02  0.000000  0.000000  0.000000  0.000000\n",
       "2017-01-03  0.000000  0.000000  0.000000  0.003145\n",
       "2017-01-04  0.005722  0.016448  0.000000 -0.000884\n",
       "2017-01-05 -0.000771 -0.011535 -0.003750  0.001771\n",
       "...              ...       ...       ...       ...\n",
       "2020-06-19 -0.005649 -0.006095  0.005517  0.005777\n",
       "2020-06-20  0.000000  0.000000  0.000000  0.000000\n",
       "2020-06-21  0.000000  0.000000  0.000000  0.000000\n",
       "2020-06-22  0.000000  0.000000 -0.001847  0.000000\n",
       "2020-06-23  0.000000  0.000000  0.000000  0.000000\n",
       "\n",
       "[1270 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_return_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnIndexReturns = index_return_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.00314498],\n",
       "       [ 0.00572227,  0.01644828,  0.        , -0.0008845 ]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnIndexReturns[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00893596539226695\n"
     ]
    }
   ],
   "source": [
    "print(linalg.expm_cond(mnIndexReturns[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
